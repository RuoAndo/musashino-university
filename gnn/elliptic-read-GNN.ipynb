{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Elliptic++ っぽいトランザクショングラフに\n",
    "GNN（GCN）を適用して可視化する完全版スクリプト。\n",
    "\n",
    "1) pandas で TXT を読み込み\n",
    "2) PyTorch Geometric の Data へ変換\n",
    "3) GCN でノード分類を学習\n",
    "4) t-SNE で埋め込み可視化\n",
    "5) サブグラフ可視化\n",
    "6) 混同行列を表示\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# ====== ファイルパス ======\n",
    "TXS_FEATURES = \"txs_features.txt\"\n",
    "TXS_CLASSES  = \"txs_classes.txt\"\n",
    "TXS_EDGES    = \"txs_edgelist.txt\"\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# ユーティリティ\n",
    "# ==========================\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def train_val_test_split(num_nodes: int,\n",
    "                         train_ratio: float = 0.6,\n",
    "                         val_ratio: float = 0.2):\n",
    "    \"\"\"\n",
    "    ノードインデックスを train / val / test にランダム分割。\n",
    "    \"\"\"\n",
    "    assert train_ratio + val_ratio < 1.0\n",
    "    perm = torch.randperm(num_nodes)\n",
    "    n_train = int(num_nodes * train_ratio)\n",
    "    n_val   = int(num_nodes * val_ratio)\n",
    "\n",
    "    train_idx = perm[:n_train]\n",
    "    val_idx   = perm[n_train:n_train + n_val]\n",
    "    test_idx  = perm[n_train + n_val:]\n",
    "\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask   = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[val_idx]     = True\n",
    "    test_mask[test_idx]   = True\n",
    "\n",
    "    return train_mask, val_mask, test_mask\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# データ読み込み & Data 変換\n",
    "# ==========================\n",
    "def load_raw_data():\n",
    "    print(\"Loading txs_features...\")\n",
    "    df_features = pd.read_csv(TXS_FEATURES)\n",
    "    print(\"  shape:\", df_features.shape)\n",
    "    print(\"  columns:\", list(df_features.columns[:10]), \"...\")\n",
    "\n",
    "    print(\"\\nLoading txs_classes...\")\n",
    "    df_classes = pd.read_csv(TXS_CLASSES)\n",
    "    print(\"  shape:\", df_classes.shape)\n",
    "    print(\"  columns:\", list(df_classes.columns))\n",
    "    if \"class\" in df_classes.columns:\n",
    "        print(\"  class unique:\", df_classes[\"class\"].unique())\n",
    "\n",
    "    print(\"\\nLoading txs_edgelist...\")\n",
    "    df_edges = pd.read_csv(TXS_EDGES)\n",
    "    print(\"  shape:\", df_edges.shape)\n",
    "    print(\"  columns:\", list(df_edges.columns))\n",
    "\n",
    "    # --- 簡単な概要 ---\n",
    "    print(\"\\n=== Features overview ===\")\n",
    "    print(df_features.head())\n",
    "    print(df_features.describe(include=\"all\"))\n",
    "    print(\"missing values (total):\",\n",
    "          int(df_features.isnull().sum().sum()))\n",
    "\n",
    "    print(\"\\n=== Features: missing per column (top 10) ===\")\n",
    "    print((df_features.isnull().sum()).sort_values(\n",
    "        ascending=False\n",
    "    ).head(10))\n",
    "\n",
    "    print(\"\\n=== Classes overview ===\")\n",
    "    if \"class\" in df_classes.columns:\n",
    "        print(df_classes[\"class\"].value_counts())\n",
    "    else:\n",
    "        print(\"WARNING: 'class' column not found in classes file.\")\n",
    "\n",
    "    print(\"\\n=== Edges overview ===\")\n",
    "    print(df_edges.head())\n",
    "\n",
    "    return df_features, df_classes, df_edges\n",
    "\n",
    "\n",
    "def build_pyg_data(df_features: pd.DataFrame,\n",
    "                   df_classes: pd.DataFrame,\n",
    "                   df_edges: pd.DataFrame) -> Data:\n",
    "    \"\"\"\n",
    "    pandas DataFrame から PyG の Data を作る。\n",
    "    - 先頭列をノードIDとみなす\n",
    "    - 特徴量は残りの数値列\n",
    "    - クラスは df_classes の 'class' をカテゴリコード化\n",
    "    \"\"\"\n",
    "    # ---- ノードID列の推定 ----\n",
    "    id_col_feat = df_features.columns[0]  # 1列目をIDとみなす\n",
    "    print(f\"\\n[build_pyg_data] using '{id_col_feat}' as node id column.\")\n",
    "\n",
    "    # ---- 特徴量行列 X ----\n",
    "    feature_cols = [c for c in df_features.columns if c != id_col_feat]\n",
    "    x_np = df_features[feature_cols].to_numpy(dtype=float)\n",
    "    x = torch.tensor(x_np, dtype=torch.float)\n",
    "    num_nodes = x.size(0)\n",
    "    print(\"[build_pyg_data] x shape:\", x.shape)\n",
    "\n",
    "    # ---- ノードID -> インデックスのマッピング ----\n",
    "    node_ids = df_features[id_col_feat].values\n",
    "    id2idx = {int(nid): i for i, nid in enumerate(node_ids)}\n",
    "\n",
    "    # ---- クラスラベル y ----\n",
    "    if \"class\" not in df_classes.columns:\n",
    "        raise ValueError(\"df_classes に 'class' 列がありません。\")\n",
    "\n",
    "    # classes 側の ID 列を決める（features 側と同じ名前を優先）\n",
    "    if id_col_feat in df_classes.columns:\n",
    "        id_col_cls = id_col_feat\n",
    "    else:\n",
    "        # 苦し紛れだが、最初の列をIDとみなす\n",
    "        id_col_cls = df_classes.columns[0]\n",
    "        print(f\"[build_pyg_data] WARNING: using '{id_col_cls}' as id col for classes.\")\n",
    "\n",
    "    # classes を features の順番にそろえる\n",
    "    cls_series = (\n",
    "        df_classes\n",
    "        .set_index(id_col_cls)[\"class\"]\n",
    "        .reindex(node_ids)\n",
    "    )\n",
    "    # 未ラベルは NaN になる\n",
    "    labeled_mask_np = ~cls_series.isna().values\n",
    "\n",
    "    # カテゴリコード化（文字列ラベル OK）\n",
    "    cls_cat = cls_series.astype(\"category\")\n",
    "    y_codes = cls_cat.cat.codes.to_numpy()  # NaN -> -1\n",
    "    y = torch.tensor(y_codes, dtype=torch.long)\n",
    "\n",
    "    # ラベルのカテゴリ一覧\n",
    "    classes = list(cls_cat.cat.categories)\n",
    "    print(\"[build_pyg_data] classes:\", classes)\n",
    "    print(\"[build_pyg_data] labeled nodes:\",\n",
    "          int(labeled_mask_np.sum()), \"/\", num_nodes)\n",
    "\n",
    "    # ---- エッジ edge_index ----\n",
    "    edge_cols = df_edges.columns[:2]  # 最初の2列を (src, dst) とみなす\n",
    "    src_raw = df_edges[edge_cols[0]].values\n",
    "    dst_raw = df_edges[edge_cols[1]].values\n",
    "\n",
    "    src_idx = []\n",
    "    dst_idx = []\n",
    "    missing_edges = 0\n",
    "    for u, v in zip(src_raw, dst_raw):\n",
    "        u = int(u)\n",
    "        v = int(v)\n",
    "        if u in id2idx and v in id2idx:\n",
    "            src_idx.append(id2idx[u])\n",
    "            dst_idx.append(id2idx[v])\n",
    "        else:\n",
    "            missing_edges += 1\n",
    "\n",
    "    if missing_edges > 0:\n",
    "        print(f\"[build_pyg_data] skipped edges with unknown nodes: {missing_edges}\")\n",
    "\n",
    "    edge_index = torch.tensor([src_idx, dst_idx], dtype=torch.long)\n",
    "    print(\"[build_pyg_data] edge_index shape:\", edge_index.shape)\n",
    "\n",
    "    # ---- Data オブジェクト ----\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    # マスク作成（ラベル付きノードのみ学習対象）\n",
    "    train_mask, val_mask, test_mask = train_val_test_split(num_nodes)\n",
    "    labeled_mask = torch.tensor(labeled_mask_np, dtype=torch.bool)\n",
    "\n",
    "    data.train_mask = train_mask & labeled_mask\n",
    "    data.val_mask   = val_mask   & labeled_mask\n",
    "    data.test_mask  = test_mask  & labeled_mask\n",
    "\n",
    "    print(\"[build_pyg_data] train/val/test labeled counts:\",\n",
    "          int(data.train_mask.sum()),\n",
    "          int(data.val_mask.sum()),\n",
    "          int(data.test_mask.sum()))\n",
    "\n",
    "    # エッジ統計\n",
    "    print(\"[build_pyg_data] duplicate edges:\",\n",
    "          int(df_edges.duplicated(subset=edge_cols).sum()))\n",
    "\n",
    "    try:\n",
    "        edge_pairs = set(map(tuple, df_edges[edge_cols].values))\n",
    "        reverse_count = sum((v, u) in edge_pairs for (u, v) in edge_pairs)\n",
    "        print(\"[build_pyg_data] reverse edge count:\", reverse_count)\n",
    "    except Exception:\n",
    "        print(\"[build_pyg_data] reverse edge check failed\")\n",
    "\n",
    "    return data, classes\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# GCN モデル\n",
    "# ==========================\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden_dim: int, out_dim: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.lin   = nn.Linear(hidden_dim, out_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, return_embeddings=False):\n",
    "        # 2層GCN + 全結合\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        embeddings = x  # ここを可視化に使う\n",
    "\n",
    "        logits = self.lin(x)\n",
    "        if return_embeddings:\n",
    "            return logits, embeddings\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 学習 & 評価\n",
    "# ==========================\n",
    "def evaluate(model: nn.Module, data: Data, split: str):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    y = data.y.to(device)\n",
    "\n",
    "    if split == \"train\":\n",
    "        mask = data.train_mask\n",
    "    elif split == \"val\":\n",
    "        mask = data.val_mask\n",
    "    elif split == \"test\":\n",
    "        mask = data.test_mask\n",
    "    else:\n",
    "        raise ValueError(\"split must be 'train', 'val' or 'test'\")\n",
    "\n",
    "    mask = mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, edge_index)\n",
    "        pred = logits.argmax(dim=-1)\n",
    "\n",
    "    if mask.sum() == 0:\n",
    "        return None, None\n",
    "\n",
    "    loss = F.cross_entropy(\n",
    "        logits[mask],\n",
    "        y[mask],\n",
    "        reduction=\"mean\"\n",
    "    )\n",
    "    correct = (pred[mask] == y[mask]).sum().item()\n",
    "    acc = correct / int(mask.sum())\n",
    "    return loss.item(), acc\n",
    "\n",
    "\n",
    "def train_gcn(data: Data, num_classes: int,\n",
    "              hidden_dim: int = 64,\n",
    "              lr: float = 1e-3,\n",
    "              epochs: int = 50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"[train_gcn] device:\", device)\n",
    "\n",
    "    model = GCN(\n",
    "        in_dim=data.num_node_features,\n",
    "        hidden_dim=hidden_dim,\n",
    "        out_dim=num_classes\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "    data = data.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        # train_mask かつ ラベル付きのノードのみ\n",
    "        mask = data.train_mask\n",
    "        loss = F.cross_entropy(\n",
    "            logits[mask],\n",
    "            data.y[mask],\n",
    "            reduction=\"mean\"\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            train_loss, train_acc = evaluate(model, data, \"train\")\n",
    "            val_loss, val_acc     = evaluate(model, data, \"val\")\n",
    "            print(f\"[Epoch {epoch:03d}] \"\n",
    "                  f\"train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
    "                  f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\")\n",
    "\n",
    "    # 最終テスト\n",
    "    test_loss, test_acc = evaluate(model, data, \"test\")\n",
    "    print(f\"\\n[Test] loss={test_loss:.4f} acc={test_acc:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 可視化 (t-SNE / サブグラフ / 混同行列)\n",
    "# ==========================\n",
    "def visualize_embeddings_tsne(model: nn.Module, data: Data,\n",
    "                              title: str = \"GNN embeddings (t-SNE)\",\n",
    "                              max_nodes: int = 2000):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    y = data.y.cpu().numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits, z = model(x, edge_index, return_embeddings=True)\n",
    "        y_pred = logits.argmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    z_np = z.cpu().numpy()\n",
    "    N = z_np.shape[0]\n",
    "\n",
    "    # ノード数が多い場合はサンプリング\n",
    "    if N > max_nodes:\n",
    "        idx = np.random.choice(N, size=max_nodes, replace=False)\n",
    "        z_np = z_np[idx]\n",
    "        y = y[idx]\n",
    "        y_pred = y_pred[idx]\n",
    "        print(f\"[t-SNE] sampled {max_nodes}/{N} nodes for visualization.\")\n",
    "    else:\n",
    "        idx = np.arange(N)\n",
    "\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        random_state=0,\n",
    "        perplexity=30,\n",
    "        init=\"pca\",\n",
    "        learning_rate=\"auto\"\n",
    "    )\n",
    "    z_2d = tsne.fit_transform(z_np)\n",
    "\n",
    "    # クラスごとに色分け\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    classes = np.unique(y)\n",
    "    for c in classes:\n",
    "        mask = (y == c)\n",
    "        plt.scatter(\n",
    "            z_2d[mask, 0],\n",
    "            z_2d[mask, 1],\n",
    "            s=8,\n",
    "            alpha=0.6,\n",
    "            label=f\"class {c}\"\n",
    "        )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"t-SNE dim 1\")\n",
    "    plt.ylabel(\"t-SNE dim 2\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 正解 / 誤り\n",
    "    correct = (y == y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(\n",
    "        z_2d[correct, 0],\n",
    "        z_2d[correct, 1],\n",
    "        s=8,\n",
    "        alpha=0.6,\n",
    "        label=\"correct\"\n",
    "    )\n",
    "    plt.scatter(\n",
    "        z_2d[~correct, 0],\n",
    "        z_2d[~correct, 1],\n",
    "        s=16,\n",
    "        alpha=0.8,\n",
    "        marker=\"x\",\n",
    "        label=\"wrong\"\n",
    "    )\n",
    "    plt.title(\"Correct vs wrong predictions\")\n",
    "    plt.xlabel(\"t-SNE dim 1\")\n",
    "    plt.ylabel(\"t-SNE dim 2\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_subgraph_with_predictions(model: nn.Module,\n",
    "                                        data: Data,\n",
    "                                        num_nodes: int = 300,\n",
    "                                        use_pred: bool = True,\n",
    "                                        title: str = \"Subgraph with GNN predictions\"):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    y_true = data.y.cpu().numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, edge_index)\n",
    "        y_pred = logits.argmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    labels_for_color = y_pred if use_pred else y_true\n",
    "\n",
    "    # PyG -> NetworkX\n",
    "    G = to_networkx(\n",
    "        data,\n",
    "        to_undirected=True,\n",
    "        node_attrs=None,\n",
    "        edge_attrs=None\n",
    "    )\n",
    "\n",
    "    all_nodes = np.array(G.nodes())\n",
    "    if len(all_nodes) > num_nodes:\n",
    "        sampled_nodes = np.random.choice(all_nodes, size=num_nodes, replace=False)\n",
    "    else:\n",
    "        sampled_nodes = all_nodes\n",
    "\n",
    "    H = G.subgraph(sampled_nodes)\n",
    "    pos = nx.spring_layout(H, seed=0)\n",
    "\n",
    "    node_colors = [labels_for_color[n] for n in H.nodes()]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    nodes = nx.draw_networkx_nodes(\n",
    "        H,\n",
    "        pos,\n",
    "        node_size=50,\n",
    "        node_color=node_colors,\n",
    "        cmap=\"tab10\"\n",
    "    )\n",
    "    nx.draw_networkx_edges(\n",
    "        H,\n",
    "        pos,\n",
    "        width=0.5,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    plt.colorbar(nodes, label=\"class (true/pred)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_confusion_matrix(model: nn.Module, data: Data,\n",
    "                               classes=None,\n",
    "                               title: str = \"Confusion matrix\"):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    x = data.x.to(device)\n",
    "    edge_index = data.edge_index.to(device)\n",
    "    y_true = data.y.cpu().numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x, edge_index)\n",
    "        y_pred = logits.argmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm,\n",
    "        display_labels=classes if classes is not None else None\n",
    "    )\n",
    "    disp.plot(values_format=\"d\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# main\n",
    "# ==========================\n",
    "def main():\n",
    "    set_seed(42)\n",
    "\n",
    "    # 1) pandas で読み込み & 概要\n",
    "    df_features, df_classes, df_edges = load_raw_data()\n",
    "\n",
    "    # 2) PyG Data 化\n",
    "    data, classes = build_pyg_data(df_features, df_classes, df_edges)\n",
    "\n",
    "    # 3) GCN で学習\n",
    "    model = train_gcn(data, num_classes=len(classes), hidden_dim=64,\n",
    "                      lr=1e-3, epochs=50)\n",
    "\n",
    "    # 4) 可視化\n",
    "    visualize_embeddings_tsne(model, data)\n",
    "    visualize_subgraph_with_predictions(\n",
    "        model,\n",
    "        data,\n",
    "        num_nodes=300,\n",
    "        use_pred=True,\n",
    "        title=\"Subgraph with predicted labels\"\n",
    "    )\n",
    "    visualize_confusion_matrix(model, data, classes=classes)\n",
    "\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
