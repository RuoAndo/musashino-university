{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fbfeb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Cannot find DGL C++ graphbolt library at C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dgl\\graphbolt\\graphbolt_pytorch_2.6.0.dll",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdgl\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdgl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiLayerNeighborSampler, MultiLayerFullNeighborSampler, DataLoader\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 便利関数\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dgl\\__init__.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m enable_verbose_logging  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend_name, load_backend  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     container,\n\u001b[0;32m     18\u001b[0m     cuda,\n\u001b[0;32m     19\u001b[0m     dataloading,\n\u001b[0;32m     20\u001b[0m     function,\n\u001b[0;32m     21\u001b[0m     ops,\n\u001b[0;32m     22\u001b[0m     random,\n\u001b[0;32m     23\u001b[0m     sampling,\n\u001b[0;32m     24\u001b[0m     storages,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__, DGLError\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     extract_ext_funcs,\n\u001b[0;32m     29\u001b[0m     get_global_func,\n\u001b[0;32m     30\u001b[0m     list_global_func_names,\n\u001b[0;32m     31\u001b[0m     register_func,\n\u001b[0;32m     32\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dgl\\dataloading\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m F\u001b[38;5;241m.\u001b[39mget_preferred_backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspot_target\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_dataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dgl\\dataloading\\dataloader.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m batch \u001b[38;5;28;01mas\u001b[39;00m batch_graphs\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPUCache\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistGraph\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LazyFeature\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheterograph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DGLGraph\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dgl\\distributed\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exit_client, initialize\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_dataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistDataLoader\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_graph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistGraph, DistGraphServer, edge_split, node_split\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DistTensor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_partition_book\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphPartitionBook, PartitionPolicy\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dgl\\distributed\\dist_graph.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MutableMapping\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m F, graphbolt \u001b[38;5;28;01mas\u001b[39;00m gb, heterograph_index\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndarray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m empty_shared_mem\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALL, DGLError, EID, ETYPE, is_all, NID\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dgl\\graphbolt\\__init__.py:36\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=W0703\u001b[39;00m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load Graphbolt C++ library\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mload_graphbolt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# pylint: disable=wrong-import-position\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dgl\\graphbolt\\__init__.py:26\u001b[0m, in \u001b[0;36mload_graphbolt\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraphbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, basename)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find DGL C++ graphbolt library at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     torch\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mload_library(path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Cannot find DGL C++ graphbolt library at C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dgl\\graphbolt\\graphbolt_pytorch_2.6.0.dll"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl.dataloading import MultiLayerNeighborSampler, MultiLayerFullNeighborSampler, DataLoader\n",
    "\n",
    "# ---------------------------------\n",
    "# 便利関数\n",
    "# ---------------------------------\n",
    "def log(s: str):\n",
    "    print(s, flush=True)\n",
    "\n",
    "def ensure_dir(d: str):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def infer_feature_cols(header_cols):\n",
    "    # txId, Time step は特徴に入れない（必要なら後で足せます）\n",
    "    drop = {\"txId\", \"Time step\"}\n",
    "    return [c for c in header_cols if c not in drop]\n",
    "\n",
    "def build_tx_ids(features_path: str, out_path: str):\n",
    "    log(\"[A] txId を features から抽出...\")\n",
    "    tx = pd.read_csv(features_path, usecols=[\"txId\"], dtype={\"txId\": np.int64})\n",
    "    tx_ids = tx[\"txId\"].to_numpy(np.int64)\n",
    "    np.save(out_path, tx_ids)\n",
    "    log(f\"[A] N={len(tx_ids)}  saved: {out_path}\")\n",
    "    return tx_ids\n",
    "\n",
    "def build_features_memmap(features_path: str, tx_ids: np.ndarray, out_memmap_path: str, out_cols_path: str, chunksize: int):\n",
    "    log(\"[B] features を memmap に変換...\")\n",
    "    header = pd.read_csv(features_path, nrows=0)\n",
    "    feat_cols = infer_feature_cols(list(header.columns))\n",
    "    D = len(feat_cols)\n",
    "    np.save(out_cols_path, np.array(feat_cols, dtype=object))\n",
    "    log(f\"[B] feature dim D={D}  cols saved: {out_cols_path}\")\n",
    "\n",
    "    N = len(tx_ids)\n",
    "    mm = np.memmap(out_memmap_path, dtype=np.float32, mode=\"w+\", shape=(N, D))\n",
    "\n",
    "    reader = pd.read_csv(\n",
    "        features_path,\n",
    "        usecols=feat_cols,\n",
    "        dtype={c: np.float32 for c in feat_cols},\n",
    "        chunksize=chunksize,\n",
    "    )\n",
    "\n",
    "    offset = 0\n",
    "    for chunk in reader:\n",
    "        arr = chunk.to_numpy(np.float32, copy=False)\n",
    "        n = arr.shape[0]\n",
    "        mm[offset:offset+n, :] = arr\n",
    "        offset += n\n",
    "        if offset % 1_000_000 < chunksize:\n",
    "            log(f\"[B] written: {offset}/{N}\")\n",
    "\n",
    "    mm.flush()\n",
    "    if offset != N:\n",
    "        raise RuntimeError(f\"features 行数不一致: wrote={offset} N={N}\")\n",
    "    log(f\"[B] memmap saved: {out_memmap_path}\")\n",
    "\n",
    "def build_labels(classes_path: str, tx_ids: np.ndarray, out_path: str):\n",
    "    \"\"\"\n",
    "    典型的に class: 1=illicit, 2=licit, 3=unknown\n",
    "    ここでは学習用に y: illicit=1, licit=0, unknown=-1 に変換\n",
    "    \"\"\"\n",
    "    log(\"[C] labels y を作成（unknown=-1）...\")\n",
    "    y = np.full((len(tx_ids),), -1, dtype=np.int8)\n",
    "\n",
    "    idx = pd.Index(tx_ids)  # 高速マッピング用\n",
    "    df = pd.read_csv(classes_path, dtype={\"txId\": np.int64, \"class\": np.int16})\n",
    "\n",
    "    loc = idx.get_indexer(df[\"txId\"].to_numpy(np.int64))\n",
    "    ok = loc >= 0\n",
    "    loc = loc[ok]\n",
    "    cls = df[\"class\"].to_numpy(np.int16)[ok]\n",
    "\n",
    "    # 変換\n",
    "    # 1 -> illicit(1), 2 -> licit(0), 3 -> unknown(-1)\n",
    "    y_vals = np.full_like(cls, -1, dtype=np.int8)\n",
    "    y_vals[cls == 1] = 1\n",
    "    y_vals[cls == 2] = 0\n",
    "    y_vals[cls == 3] = -1\n",
    "\n",
    "    y[loc] = y_vals\n",
    "    np.save(out_path, y)\n",
    "    log(f\"[C] saved: {out_path}  labeled={(y!=-1).sum()}  illicit={(y==1).sum()}  licit={(y==0).sum()}  unknown={(y==-1).sum()}\")\n",
    "    return y\n",
    "\n",
    "def build_edges(edges_path: str, tx_ids: np.ndarray, out_path: str):\n",
    "    log(\"[D] edges を txId -> index に変換...\")\n",
    "    idx = pd.Index(tx_ids)\n",
    "\n",
    "    edges = pd.read_csv(edges_path, dtype={\"txId1\": np.int64, \"txId2\": np.int64})\n",
    "    src = edges[\"txId1\"].to_numpy(np.int64)\n",
    "    dst = edges[\"txId2\"].to_numpy(np.int64)\n",
    "\n",
    "    src_i = idx.get_indexer(src)\n",
    "    dst_i = idx.get_indexer(dst)\n",
    "\n",
    "    ok = (src_i >= 0) & (dst_i >= 0)\n",
    "    src_i = src_i[ok].astype(np.int64)\n",
    "    dst_i = dst_i[ok].astype(np.int64)\n",
    "\n",
    "    edge_index = np.vstack([src_i, dst_i]).astype(np.int64)\n",
    "    np.save(out_path, edge_index)\n",
    "    log(f\"[D] kept edges: {edge_index.shape[1]}  saved: {out_path}\")\n",
    "    return edge_index\n",
    "\n",
    "# ---------------------------------\n",
    "# GraphSAGE\n",
    "# ---------------------------------\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_dim: int, hid: int, emb_dim: int, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.sage1 = dgl.nn.SAGEConv(in_dim, hid, aggregator_type=\"mean\")\n",
    "        self.sage2 = dgl.nn.SAGEConv(hid, emb_dim, aggregator_type=\"mean\")\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, blocks, x):\n",
    "        h = self.sage1(blocks[0], x)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h = self.sage2(blocks[1], h)\n",
    "        return h  # 埋め込み\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--features\", default=\"txs_features.txt\")\n",
    "    ap.add_argument(\"--classes\",  default=\"txs_classes.txt\")\n",
    "    ap.add_argument(\"--edges\",    default=\"txs_edgelist.txt\")\n",
    "    ap.add_argument(\"--workdir\",  default=\"./_prep_dgl\")\n",
    "    ap.add_argument(\"--emb_dim\",  type=int, default=64)\n",
    "    ap.add_argument(\"--hid_dim\",  type=int, default=128)\n",
    "    ap.add_argument(\"--epochs\",   type=int, default=3)\n",
    "    ap.add_argument(\"--batch\",    type=int, default=4096)\n",
    "    ap.add_argument(\"--neighbors\", default=\"15,10\")  # 2層\n",
    "    ap.add_argument(\"--lr\",       type=float, default=1e-3)\n",
    "    ap.add_argument(\"--seed\",     type=int, default=42)\n",
    "    ap.add_argument(\"--chunksize\",type=int, default=200000)\n",
    "    ap.add_argument(\"--bidirected\", action=\"store_true\", help=\"グラフを双方向化（推奨）\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    set_seed(args.seed)\n",
    "    ensure_dir(args.workdir)\n",
    "\n",
    "    txids_path = os.path.join(args.workdir, \"tx_ids.npy\")\n",
    "    cols_path  = os.path.join(args.workdir, \"feature_cols.npy\")\n",
    "    x_mm_path  = os.path.join(args.workdir, \"x_float32.memmap\")\n",
    "    y_path     = os.path.join(args.workdir, \"y_int8.npy\")\n",
    "    e_path     = os.path.join(args.workdir, \"edge_index.npy\")\n",
    "    emb_path   = os.path.join(args.workdir, f\"emb_{args.emb_dim}d_float32.memmap\")\n",
    "\n",
    "    # A: tx_ids\n",
    "    if os.path.exists(txids_path):\n",
    "        tx_ids = np.load(txids_path)\n",
    "        log(f\"[A] reuse: {txids_path}  N={len(tx_ids)}\")\n",
    "    else:\n",
    "        tx_ids = build_tx_ids(args.features, txids_path)\n",
    "\n",
    "    # B: features memmap\n",
    "    if os.path.exists(x_mm_path) and os.path.exists(cols_path):\n",
    "        feat_cols = np.load(cols_path, allow_pickle=True)\n",
    "        D = len(feat_cols)\n",
    "        log(f\"[B] reuse: {x_mm_path}  shape=({len(tx_ids)},{D})\")\n",
    "    else:\n",
    "        build_features_memmap(args.features, tx_ids, x_mm_path, cols_path, args.chunksize)\n",
    "        feat_cols = np.load(cols_path, allow_pickle=True)\n",
    "        D = len(feat_cols)\n",
    "\n",
    "    # C: labels\n",
    "    if os.path.exists(y_path):\n",
    "        y = np.load(y_path)\n",
    "        log(f\"[C] reuse: {y_path}\")\n",
    "    else:\n",
    "        y = build_labels(args.classes, tx_ids, y_path)\n",
    "\n",
    "    # D: edges\n",
    "    if os.path.exists(e_path):\n",
    "        edge_index = np.load(e_path)\n",
    "        log(f\"[D] reuse: {e_path}  E={edge_index.shape[1]}\")\n",
    "    else:\n",
    "        edge_index = build_edges(args.edges, tx_ids, e_path)\n",
    "\n",
    "    N = len(tx_ids)\n",
    "    src = torch.from_numpy(edge_index[0])\n",
    "    dst = torch.from_numpy(edge_index[1])\n",
    "\n",
    "    g = dgl.graph((src, dst), num_nodes=N)\n",
    "    if args.bidirected:\n",
    "        g = dgl.to_bidirected(g, copy_ndata=False)\n",
    "        log(\"[INFO] graph -> bidirected\")\n",
    "    g = dgl.add_self_loop(g)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    log(f\"[INFO] device={device}\")\n",
    "\n",
    "    # features: memmap -> torch tensor（CPU上の参照）\n",
    "    x_mm = np.memmap(x_mm_path, dtype=np.float32, mode=\"r\", shape=(N, D))\n",
    "    x = torch.from_numpy(x_mm)  # 大きいので “参照” 前提\n",
    "    g.ndata[\"x\"] = x\n",
    "    g.ndata[\"y\"] = torch.from_numpy(y.astype(np.int64))\n",
    "\n",
    "    # 学習対象ノード（unknown=-1 を除外）\n",
    "    labeled_mask = (g.ndata[\"y\"] != -1)\n",
    "    labeled_idx = torch.nonzero(labeled_mask, as_tuple=False).squeeze()\n",
    "\n",
    "    # train/val split\n",
    "    perm = labeled_idx[torch.randperm(labeled_idx.numel())]\n",
    "    n_train = int(0.8 * perm.numel())\n",
    "    train_idx = perm[:n_train]\n",
    "    val_idx   = perm[n_train:]\n",
    "\n",
    "    # サンプラー\n",
    "    neigh = [int(v) for v in args.neighbors.split(\",\")]\n",
    "    sampler = MultiLayerNeighborSampler(neigh)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        g, train_idx, sampler,\n",
    "        batch_size=args.batch, shuffle=True, drop_last=False, num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        g, val_idx, sampler,\n",
    "        batch_size=args.batch, shuffle=False, drop_last=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    model = SAGE(D, args.hid_dim, args.emb_dim, dropout=0.2).to(device)\n",
    "    clf = nn.Linear(args.emb_dim, 2).to(device)\n",
    "    opt = torch.optim.Adam(list(model.parameters()) + list(clf.parameters()), lr=args.lr, weight_decay=1e-4)\n",
    "\n",
    "    def run_eval():\n",
    "        model.eval(); clf.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for input_nodes, output_nodes, blocks in val_loader:\n",
    "                blocks = [b.to(device) for b in blocks]\n",
    "                xb = blocks[0].srcdata[\"x\"].to(device)\n",
    "                yb = blocks[-1].dstdata[\"y\"].to(device)\n",
    "                z = model(blocks, xb)\n",
    "                logits = clf(z)\n",
    "                pred = logits.argmax(dim=-1)\n",
    "                correct += int((pred == yb).sum().item())\n",
    "                total += int(yb.numel())\n",
    "        return correct / max(1, total)\n",
    "\n",
    "    # 1) まず学習（ノード分類で埋め込みを“意味あるもの”にする）\n",
    "    log(\"[TRAIN] start\")\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        model.train(); clf.train()\n",
    "        total_loss = 0.0\n",
    "        steps = 0\n",
    "        for input_nodes, output_nodes, blocks in train_loader:\n",
    "            blocks = [b.to(device) for b in blocks]\n",
    "            xb = blocks[0].srcdata[\"x\"].to(device)\n",
    "            yb = blocks[-1].dstdata[\"y\"].to(device)  # 0/1 のみ\n",
    "            z = model(blocks, xb)\n",
    "            logits = clf(z)\n",
    "            loss = F.cross_entropy(logits, yb)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += float(loss.item())\n",
    "            steps += 1\n",
    "\n",
    "        acc = run_eval()\n",
    "        log(f\"[TRAIN] epoch={epoch} loss={total_loss/max(1,steps):.4f} val_acc={acc:.4f}\")\n",
    "\n",
    "    # 2) 全ノードの 64次元埋め込み生成（バッチで全ノード推論）\n",
    "    log(\"[EMB] generate embeddings for ALL nodes ...\")\n",
    "    full_sampler = MultiLayerFullNeighborSampler(2)  # 2層分を完全近傍で推論\n",
    "    all_idx = torch.arange(N)\n",
    "\n",
    "    full_loader = DataLoader(\n",
    "        g, all_idx, full_sampler,\n",
    "        batch_size=args.batch, shuffle=False, drop_last=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    emb_mm = np.memmap(emb_path, dtype=np.float32, mode=\"w+\", shape=(N, args.emb_dim))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        done = 0\n",
    "        for input_nodes, output_nodes, blocks in full_loader:\n",
    "            blocks = [b.to(device) for b in blocks]\n",
    "            xb = blocks[0].srcdata[\"x\"].to(device)\n",
    "            z = model(blocks, xb)  # shape: [batch, emb_dim]\n",
    "            out_nids = output_nodes.numpy()\n",
    "            emb_mm[out_nids, :] = z.detach().cpu().numpy().astype(np.float32, copy=False)\n",
    "            done += len(out_nids)\n",
    "            if done % 1_000_000 < args.batch:\n",
    "                log(f\"[EMB] done nodes: {done}/{N}\")\n",
    "\n",
    "    emb_mm.flush()\n",
    "    log(f\"[EMB] saved: {emb_path}\")\n",
    "    log(\"[DONE]\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
