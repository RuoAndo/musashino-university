{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Hellinger 距離版\n",
    "- isolation_forest.zip を自動解凍して *-TorIP_geocoded.csv を処理\n",
    "- (1) 全ファイル間 2D-Hellinger 距離行列 (CSV/PNG)\n",
    "- (2) 隣接ペア 2D-Hellinger 時系列 (CSV/PNG)\n",
    "- (3) 距離行列の行総和（総乖離度）(PNG)\n",
    "\n",
    "※ 2D は lat と lon の 1D-Hellinger を RMS 合成\n",
    "※ 1D はヒストで確率化（微小平滑化あり）\n",
    "※ seaborn 不使用（matplotlib のみ）\n",
    "\"\"\"\n",
    "\n",
    "# ========= 設定 =========\n",
    "ZIP_PATH        = \"./isolation_forest.zip\"\n",
    "EXTRACT_DIR     = \"./isolation_forest_extracted\"\n",
    "PREFIX          = \"hellinger\"   # 出力プレフィックス\n",
    "UNIT            = \"deg\"         # \"deg\" or \"km\"\n",
    "MIN_ROWS        = 1\n",
    "Z_THR_TS        = 3.5\n",
    "OUTPUT_ENCODING = \"cp932\"       # Excel重視（UTF-8なら \"utf-8-sig\"）\n",
    "\n",
    "# ヒスト推定\n",
    "BINS        = 64                # 32〜128程度\n",
    "RANGE_MODE  = \"pooled\"          # \"pooled\"（全データ共通レンジ）/ \"pair\"\n",
    "EPS_SMOOTH  = 1e-12             # ゼロ回避\n",
    "# =======================\n",
    "\n",
    "import os, sys, csv, math, zipfile, shutil\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import font_manager, rcParams\n",
    "\n",
    "# ---------- 日本語フォント ----------\n",
    "JP_FONT_CANDIDATES = [\"Yu Gothic\", \"Meiryo\", \"Noto Sans CJK JP\", \"IPAexGothic\", \"IPAPGothic\", \"TakaoGothic\"]\n",
    "def setup_japanese_font():\n",
    "    available = {f.name for f in font_manager.fontManager.ttflist}\n",
    "    for name in JP_FONT_CANDIDATES:\n",
    "        if name in available:\n",
    "            rcParams[\"font.family\"] = \"sans-serif\"\n",
    "            rcParams[\"font.sans-serif\"] = [name]\n",
    "            break\n",
    "    rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ---------- 文字コード ----------\n",
    "READ_ENCODINGS = (\"utf-8\", \"utf-8-sig\", \"cp932\", \"iso-8859-1\")\n",
    "def open_read_fallback(path):\n",
    "    last = None\n",
    "    for enc in READ_ENCODINGS:\n",
    "        try:\n",
    "            return open(path, \"r\", encoding=enc, newline=\"\")\n",
    "        except Exception as e:\n",
    "            last = e\n",
    "    try:\n",
    "        return open(path, \"r\", newline=\"\")\n",
    "    except Exception:\n",
    "        raise last or RuntimeError(f\"cannot open {path}\")\n",
    "\n",
    "TRANSLATE_TABLE = {\n",
    "    0x2010: ord(\"-\"), 0x2011: ord(\"-\"), 0x2012: ord(\"-\"), 0x2013: ord(\"-\"),\n",
    "    0x2014: ord(\"-\"), 0x2015: ord(\"-\"), 0x2212: ord(\"-\"),\n",
    "    0x00A0: ord(\" \")\n",
    "}\n",
    "def normalize_text(s: str) -> str:\n",
    "    return s.translate(TRANSLATE_TABLE) if isinstance(s, str) else s\n",
    "\n",
    "def open_write(path):\n",
    "    return open(path, \"w\", encoding=OUTPUT_ENCODING, newline=\"\", errors=\"replace\")\n",
    "\n",
    "# ---------- CSV 読み込み ----------\n",
    "def row_has_header_like(cells):\n",
    "    if len(cells) < 4: return True\n",
    "    try:\n",
    "        float((cells[2] or \"\").strip()); float((cells[3] or \"\").strip())\n",
    "        return False\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "def load_valid_latlon(filepath):\n",
    "    lats, lons = [], []\n",
    "    with open_read_fallback(filepath) as f:\n",
    "        rdr = csv.reader(f)\n",
    "        first = next(rdr, None)\n",
    "        if first is None: return np.empty(0), np.empty(0)\n",
    "        use_header = row_has_header_like(first)\n",
    "        rows = rdr if use_header else [first] + list(rdr)\n",
    "        for row in rows:\n",
    "            if len(row) < 4: continue\n",
    "            a = (row[2] or \"\").strip(); b = (row[3] or \"\").strip()\n",
    "            if not a or not b: continue\n",
    "            try:\n",
    "                lat = float(a); lon = float(b)\n",
    "                if math.isfinite(lat) and math.isfinite(lon):\n",
    "                    lats.append(lat); lons.append(lon)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return np.array(lats, float), np.array(lons, float)\n",
    "\n",
    "# ---------- 単位換算 ----------\n",
    "def deg_to_km_scale(lat_values):\n",
    "    phi = (float(np.median(lat_values)) if len(lat_values) else 0.0) * math.pi/180.0\n",
    "    return 111.32, 111.32 * math.cos(phi)\n",
    "\n",
    "def convert_unit(lat_array, lon_array, ref_lat=None):\n",
    "    if UNIT != \"km\":\n",
    "        return lat_array, lon_array\n",
    "    ref = ref_lat if ref_lat is not None else (np.median(lat_array) if len(lat_array) else 0.0)\n",
    "    la_km, lo_km = deg_to_km_scale(np.array([ref]))\n",
    "    return lat_array * la_km, lon_array * lo_km\n",
    "\n",
    "# ---------- 1D-Hellinger 距離 ----------\n",
    "# H(P,Q) = (1/sqrt(2)) * sqrt( sum_i (sqrt(p_i) - sqrt(q_i))^2 )\n",
    "def hellinger_distance_1d(samples_a, samples_b, bins, value_range):\n",
    "    pa, _ = np.histogram(samples_a, bins=bins, range=value_range, density=False)\n",
    "    pb, _ = np.histogram(samples_b, bins=bins, range=value_range, density=False)\n",
    "    pa = pa.astype(float) + EPS_SMOOTH\n",
    "    pb = pb.astype(float) + EPS_SMOOTH\n",
    "    pa /= pa.sum(); pb /= pb.sum()\n",
    "    # Bhattacharyya coefficient BC = sum sqrt(pa*pb)\n",
    "    # H^2 = 1 - BC  （係数 1/√2 の定義もあるが、sqrt(1-BC) と等価スケール）\n",
    "    bc = float(np.sum(np.sqrt(pa * pb)))\n",
    "    h2 = max(0.0, 1.0 - bc)\n",
    "    return float(np.sqrt(h2))\n",
    "\n",
    "# ---------- 2D 合成 ----------\n",
    "def composite_hellinger_distance_2d(lat_a, lon_a, lat_b, lon_b, bins_lat, range_lat, bins_lon, range_lon):\n",
    "    ref_lat = np.median(np.concatenate([lat_a, lat_b])) if (len(lat_a)+len(lat_b)) else 0.0\n",
    "    lat_a2, lon_a2 = convert_unit(lat_a, lon_a, ref_lat)\n",
    "    lat_b2, lon_b2 = convert_unit(lat_b, lon_b, ref_lat)\n",
    "    d_lat = hellinger_distance_1d(lat_a2, lat_b2, bins_lat, range_lat)\n",
    "    d_lon = hellinger_distance_1d(lon_a2, lon_b2, bins_lon, range_lon)\n",
    "    return float(np.hypot(d_lat, d_lon))\n",
    "\n",
    "# ---------- ロバストZ ----------\n",
    "def robust_zscore(x: np.ndarray) -> np.ndarray:\n",
    "    if x.size == 0: return np.zeros(0, float)\n",
    "    med = np.median(x); mad = np.median(np.abs(x - med))\n",
    "    if mad == 0: return np.zeros_like(x, float)\n",
    "    return 0.6745 * (x - med) / mad\n",
    "\n",
    "# ---------- ファイル名日時 ----------\n",
    "def date_from_filename(fname: str):\n",
    "    base = os.path.basename(fname); key = base.split(\"-\")[0]\n",
    "    try:\n",
    "        dt = datetime.strptime(key[:14], \"%Y%m%d%H%M%S\")\n",
    "        return dt.date(), dt\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ---------- レンジ ----------\n",
    "def pad_range(x):\n",
    "    if x is None or x.size == 0: return (-1.0, 1.0)\n",
    "    lo, hi = float(np.min(x)), float(np.max(x))\n",
    "    if lo == hi:\n",
    "        span = 1.0 if lo == 0 else abs(lo)*0.01\n",
    "        lo -= span; hi += span\n",
    "    pad = (hi - lo) * 0.02\n",
    "    return (lo - pad, hi + pad)\n",
    "\n",
    "# ---------- メイン ----------\n",
    "def main():\n",
    "    setup_japanese_font()\n",
    "\n",
    "    # zip 展開\n",
    "    if os.path.exists(EXTRACT_DIR):\n",
    "        shutil.rmtree(EXTRACT_DIR)\n",
    "    os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
    "    if not os.path.exists(ZIP_PATH):\n",
    "        print(f\"[ERROR] zipが見つかりません: {ZIP_PATH}\", file=sys.stderr); return\n",
    "    with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
    "        z.extractall(EXTRACT_DIR)\n",
    "\n",
    "    # 対象CSV探索\n",
    "    csv_files = []\n",
    "    for root, _, files in os.walk(EXTRACT_DIR):\n",
    "        for f in files:\n",
    "            if f.endswith(\"TorIP_geocoded.csv\"):\n",
    "                csv_files.append(os.path.join(root, f))\n",
    "    if len(csv_files) < 2:\n",
    "        print(\"[ERROR] 有効CSVが2件未満です。\", file=sys.stderr); return\n",
    "\n",
    "    # 読み込み\n",
    "    recs = []  # (day, dt_full, path, lats, lons)\n",
    "    for f in sorted(csv_files):\n",
    "        d = date_from_filename(f)\n",
    "        if d is None:\n",
    "            print(f\"[WARN] 日付抽出に失敗: {f}\", file=sys.stderr); continue\n",
    "        day, dt_full = d\n",
    "        lats, lons = load_valid_latlon(f)\n",
    "        if len(lats) >= MIN_ROWS and len(lons) >= MIN_ROWS:\n",
    "            recs.append((day, dt_full, f, lats, lons))\n",
    "        else:\n",
    "            print(f\"[WARN] 有効行不足: {f}\", file=sys.stderr)\n",
    "    if len(recs) < 2:\n",
    "        print(\"[ERROR] 有効データが2件未満です。\", file=sys.stderr); return\n",
    "\n",
    "    # 日時で整列\n",
    "    recs.sort(key=lambda t: t[1])\n",
    "    base_names = [os.path.splitext(os.path.basename(r[2]))[0] for r in recs]\n",
    "    n = len(recs)\n",
    "\n",
    "    # レンジ（pooled）\n",
    "    all_lat = np.concatenate([r[3] for r in recs]) if RANGE_MODE==\"pooled\" else None\n",
    "    all_lon = np.concatenate([r[4] for r in recs]) if RANGE_MODE==\"pooled\" else None\n",
    "    if UNIT == \"km\":\n",
    "        ref_lat = float(np.median(all_lat)) if (all_lat is not None and len(all_lat)) else 0.0\n",
    "        all_lat_km, all_lon_km = convert_unit(all_lat if all_lat is not None else np.array([]),\n",
    "                                              all_lon if all_lon is not None else np.array([]),\n",
    "                                              ref_lat)\n",
    "        lat_vals = all_lat_km if RANGE_MODE==\"pooled\" else None\n",
    "        lon_vals = all_lon_km if RANGE_MODE==\"pooled\" else None\n",
    "    else:\n",
    "        lat_vals = all_lat if RANGE_MODE==\"pooled\" else None\n",
    "        lon_vals = all_lon if RANGE_MODE==\"pooled\" else None\n",
    "    range_lat = pad_range(lat_vals) if RANGE_MODE==\"pooled\" else None\n",
    "    range_lon = pad_range(lon_vals) if RANGE_MODE==\"pooled\" else None\n",
    "\n",
    "    # ---------- (1) 全ペア 2D-Hellinger 行列 ----------\n",
    "    dist = np.zeros((n, n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            la_i, lo_i = recs[i][3], recs[i][4]\n",
    "            la_j, lo_j = recs[j][3], recs[j][4]\n",
    "            if RANGE_MODE != \"pooled\":\n",
    "                rl = pad_range(np.concatenate([la_i, la_j]))\n",
    "                ro = pad_range(np.concatenate([lo_i, lo_j]))\n",
    "            else:\n",
    "                rl, ro = range_lat, range_lon\n",
    "            d = composite_hellinger_distance_2d(la_i, lo_i, la_j, lo_j,\n",
    "                                                BINS, rl, BINS, ro)\n",
    "            dist[i, j] = dist[j, i] = d\n",
    "\n",
    "    # 行列CSV（見出し付き）\n",
    "    matrix_csv = f\"{PREFIX}_matrix.csv\"\n",
    "    with open_write(matrix_csv) as w:\n",
    "        wr = csv.writer(w)\n",
    "        wr.writerow([\"\"] + [normalize_text(nm) for nm in base_names])\n",
    "        for i, nm in enumerate(base_names):\n",
    "            wr.writerow([normalize_text(nm)] + [f\"{x:.6f}\" for x in dist[i]])\n",
    "\n",
    "    # 行列のファイル順\n",
    "    files_txt = f\"{PREFIX}_files.txt\"\n",
    "    with open_write(files_txt) as w:\n",
    "        w.write(\"\\n\".join(normalize_text(nm) for nm in base_names))\n",
    "\n",
    "    # ヒートマップ\n",
    "    fig = plt.figure(figsize=(max(6, n*0.7), max(5, n*0.7)))\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(dist, aspect=\"equal\", interpolation=\"nearest\")\n",
    "    cbar = plt.colorbar(im); cbar.set_label(f\"2D Hellinger distance ({UNIT})\")\n",
    "    ax.set_xticks(range(n)); ax.set_yticks(range(n))\n",
    "    ax.set_xticklabels(base_names, rotation=70, ha=\"right\")\n",
    "    ax.set_yticklabels(base_names)\n",
    "    ax.set_title(\"2D Hellinger 距離ヒートマップ\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{PREFIX}_heatmap.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # ---------- (2) 隣接ペア 時系列 ----------\n",
    "    dt_full = [r[1] for r in recs]\n",
    "    x_dates, dist_vals, file_pair = [], [], []\n",
    "    for i in range(1, n):\n",
    "        laL, loL = recs[i-1][3], recs[i-1][4]\n",
    "        laR, loR = recs[i][3],  recs[i][4]\n",
    "        if RANGE_MODE != \"pooled\":\n",
    "            rl = pad_range(np.concatenate([laL, laR]))\n",
    "            ro = pad_range(np.concatenate([loL, loR]))\n",
    "        else:\n",
    "            rl, ro = range_lat, range_lon\n",
    "        d = composite_hellinger_distance_2d(laL, loL, laR, loR, BINS, rl, BINS, ro)\n",
    "        dist_vals.append(d)\n",
    "        mid = dt_full[i-1] + (dt_full[i] - dt_full[i-1]) / 2\n",
    "        x_dates.append(mid)\n",
    "        file_pair.append(f\"{base_names[i-1]} -> {base_names[i]}\")\n",
    "\n",
    "    x_dates   = np.array(x_dates, dtype=object)\n",
    "    dist_vals = np.array(dist_vals, float)\n",
    "    z = robust_zscore(dist_vals)\n",
    "\n",
    "    ts_csv = f\"{PREFIX}_timeseries.csv\"\n",
    "    with open_write(ts_csv) as w:\n",
    "        wr = csv.writer(w)\n",
    "        wr.writerow([\"date_mid\",\"file_pair\",\"distance_h2d\",\"z\"])\n",
    "        for i in range(len(dist_vals)):\n",
    "            wr.writerow([\n",
    "                x_dates[i].strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                normalize_text(file_pair[i]),\n",
    "                f\"{dist_vals[i]:.6f}\",\n",
    "                f\"{z[i]:.3f}\",\n",
    "            ])\n",
    "\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(x_dates, dist_vals, marker=\"o\", linestyle=\"none\")\n",
    "    ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(ax.xaxis.get_major_locator()))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "    plt.xlabel(\"date (midpoint of two consecutive files)\")\n",
    "    plt.ylabel(\"2D Hellinger distance\")\n",
    "    plt.title(\"Consecutive-pair 2D-Hellinger distance (x=mid-date)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{PREFIX}_timeseries.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # ---------- (3) 行総和 ----------\n",
    "    row_sums = dist.sum(axis=1)\n",
    "    dates_sorted = [r[1] for r in recs]\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(dates_sorted, row_sums, marker=\"o\")\n",
    "    ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(ax.xaxis.get_major_locator()))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "    plt.xlabel(\"date (from filename)\")\n",
    "    plt.ylabel(\"row-sum of 2D Hellinger distances\")\n",
    "    plt.title(\"Overall distribution deviation per day (row-sum of 2D-Hellinger)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{PREFIX}_row_sums.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    print(\"✅ 出力完了（Hellinger距離）\")\n",
    "    print(\"  \", f\"{PREFIX}_matrix.csv\")\n",
    "    print(\"  \", f\"{PREFIX}_files.txt\")\n",
    "    print(\"  \", f\"{PREFIX}_timeseries.csv\")\n",
    "    print(\"  \", f\"{PREFIX}_heatmap.png\")\n",
    "    print(\"  \", f\"{PREFIX}_timeseries.png\")\n",
    "    print(\"  \", f\"{PREFIX}_row_sums.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
