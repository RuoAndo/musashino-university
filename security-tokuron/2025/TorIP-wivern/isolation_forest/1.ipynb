{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb7f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "isoforest_batch.py\n",
    "- Tor IP位置CSV( lat, lon )で Isolation Forest を日別に実行\n",
    "- 集計CSVと、各日の異常点CSVを出力\n",
    "使い方（例）：\n",
    "    python isoforest_batch.py --zip /mnt/data/isolation_forest.zip --out /mnt/data\n",
    "\"\"\"\n",
    "import os, zipfile, argparse, pandas as pd, numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def read_csv_fix_header(csv_path: str) -> pd.DataFrame:\n",
    "    # ヘッダー行がデータ化している前提（ip,timestamp,lat,lon）\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    df.columns = [\"ip\", \"timestamp\", \"lat\", \"lon\"]\n",
    "    # 先頭行（本来のヘッダー文字列行）を除去\n",
    "    if len(df) > 0 and str(df.iloc[0,0]).lower() in (\"ip\",\"0\"):\n",
    "        df = df.drop(df.index[0])\n",
    "    # 型整形\n",
    "    df[\"lat\"] = pd.to_numeric(df[\"lat\"], errors=\"coerce\")\n",
    "    df[\"lon\"] = pd.to_numeric(df[\"lon\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"lat\",\"lon\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def run_isoforest_on_file(csv_path: str, contamination: float = 0.10, random_state: int = 42):\n",
    "    df = read_csv_fix_header(csv_path)\n",
    "    if len(df) < 10:\n",
    "        return None, None  # データが少なすぎる場合はスキップ\n",
    "    X = df[[\"lat\",\"lon\"]].values\n",
    "    iso = IsolationForest(\n",
    "        n_estimators=200,\n",
    "        contamination=contamination,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        warm_start=False\n",
    "    )\n",
    "    preds = iso.fit_predict(X)           # 1 (正常) or -1 (異常)\n",
    "    scores = iso.decision_function(X)    # 大きいほど正常、小さいほど異常\n",
    "    df_out = df.copy()\n",
    "    df_out[\"pred\"] = preds\n",
    "    df_out[\"score\"] = scores\n",
    "    return df_out, preds\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--zip\", required=False, help=\"ZIPファイル（CSV群）\")\n",
    "    ap.add_argument(\"--indir\", required=False, help=\"CSVが入ったディレクトリ（zip指定がなければこちらを使う）\")\n",
    "    ap.add_argument(\"--out\", required=True, help=\"出力ディレクトリ（集計CSVと異常CSVフォルダを作成）\")\n",
    "    ap.add_argument(\"--cont\", type=float, default=0.10, help=\"IsolationForest contamination\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    out_dir = os.path.abspath(args.out)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    anom_dir = os.path.join(out_dir, \"isoforest_anomalies\")\n",
    "    os.makedirs(anom_dir, exist_ok=True)\n",
    "\n",
    "    # 入力CSVの収集\n",
    "    work_dir = None\n",
    "    csv_files = []\n",
    "    if args.zip:\n",
    "        work_dir = os.path.join(out_dir, \"_extracted\")\n",
    "        os.makedirs(work_dir, exist_ok=True)\n",
    "        with zipfile.ZipFile(args.zip, \"r\") as z:\n",
    "            for n in z.namelist():\n",
    "                if n.lower().endswith(\".csv\"):\n",
    "                    z.extract(n, work_dir)\n",
    "                    csv_files.append(os.path.join(work_dir, n))\n",
    "    elif args.indir:\n",
    "        for root, _, files in os.walk(args.indir):\n",
    "            for f in files:\n",
    "                if f.lower().endswith(\".csv\"):\n",
    "                    csv_files.append(os.path.join(root, f))\n",
    "    else:\n",
    "        raise SystemExit(\"ZIP か indir のどちらかを指定してください。\")\n",
    "\n",
    "    csv_files = sorted(csv_files)\n",
    "\n",
    "    rows = []\n",
    "    for csv_path in csv_files:\n",
    "        try:\n",
    "            df_out, preds = run_isoforest_on_file(csv_path, contamination=args.cont)\n",
    "            base = os.path.basename(csv_path)\n",
    "            if df_out is None:\n",
    "                rows.append({\"file\": base, \"count\": 0, \"anomaly_ratio\": np.nan, \"score_mean\": np.nan, \"score_std\": np.nan})\n",
    "                continue\n",
    "\n",
    "            # 集計\n",
    "            count = len(df_out)\n",
    "            anomaly_ratio = float((df_out[\"pred\"] == -1).mean())\n",
    "            score_mean = float(df_out[\"score\"].mean())\n",
    "            score_std  = float(df_out[\"score\"].std(ddof=0))\n",
    "\n",
    "            # 異常のみ保存\n",
    "            anom = df_out[df_out[\"pred\"] == -1].copy()\n",
    "            anom_out = os.path.join(anom_dir, base.replace(\".csv\", \"_anomalies.csv\"))\n",
    "            anom.to_csv(anom_out, index=False, encoding=\"utf-8\")\n",
    "\n",
    "            rows.append({\n",
    "                \"file\": base,\n",
    "                \"count\": count,\n",
    "                \"anomaly_ratio\": round(anomaly_ratio, 6),\n",
    "                \"score_mean\": round(score_mean, 6),\n",
    "                \"score_std\": round(score_std, 6),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            rows.append({\"file\": os.path.basename(csv_path), \"count\": -1, \"anomaly_ratio\": np.nan, \"score_mean\": np.nan, \"score_std\": np.nan, \"error\": str(e)})\n",
    "\n",
    "    summary = pd.DataFrame(rows)\n",
    "    summary_path = os.path.join(out_dir, \"isoforest_summary.csv\")\n",
    "    summary.to_csv(summary_path, index=False, encoding=\"utf-8\")\n",
    "    print(summary_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
